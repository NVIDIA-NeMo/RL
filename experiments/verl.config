{
  "_wandb": {
    "value": {
      "cli_version": "0.19.11",
      "m": [],
      "python_version": "3.10.12",
      "t": {
        "1": [
          1,
          5,
          11,
          30,
          41,
          49,
          50,
          51,
          53,
          55,
          71,
          95,
          98,
          105
        ],
        "2": [
          1,
          5,
          11,
          30,
          41,
          49,
          50,
          51,
          53,
          55,
          71,
          95,
          98,
          105
        ],
        "3": [
          13,
          16,
          23,
          55,
          61
        ],
        "4": "3.10.12",
        "5": "0.19.11",
        "6": "4.51.1",
        "8": [
          5
        ],
        "12": "0.19.11",
        "13": "linux-x86_64"
      }
    }
  },
  "actor_rollout_ref": {
    "value": {
      "actor": {
        "checkpoint": {
          "load_contents": [
            "model",
            "optimizer",
            "extra"
          ],
          "save_contents": [
            "model",
            "optimizer",
            "extra"
          ]
        },
        "clip_ratio": 0.2,
        "clip_ratio_c": 3,
        "clip_ratio_high": 0.2,
        "clip_ratio_low": 0.2,
        "entropy_checkpointing": false,
        "entropy_coeff": 0,
        "entropy_from_logits_with_chunking": false,
        "fsdp_config": {
          "forward_prefetch": false,
          "fsdp_size": -1,
          "grad_offload": false,
          "offload_policy": false,
          "optimizer_offload": false,
          "param_offload": false,
          "reshard_after_forward": true,
          "wrap_policy": {
            "min_num_params": 0
          }
        },
        "grad_clip": 1,
        "kl_loss_coef": 0,
        "kl_loss_type": "low_var_kl",
        "loss_agg_mode": "token-mean",
        "optim": {
          "lr": 0.000001,
          "lr_warmup_steps": -1,
          "lr_warmup_steps_ratio": 0,
          "min_lr_ratio": 0,
          "num_cycles": 0.5,
          "total_training_steps": 10770,
          "warmup_style": "constant",
          "weight_decay": 0.01
        },
        "policy_loss": {
          "clip_cov_lb": 1,
          "clip_cov_ratio": 0.0002,
          "clip_cov_ub": 5,
          "kl_cov_ratio": 0.0002,
          "loss_mode": "vanilla",
          "ppo_kl_coef": 0.1
        },
        "ppo_epochs": 1,
        "ppo_max_token_len_per_gpu": 16384,
        "ppo_micro_batch_size": null,
        "ppo_micro_batch_size_per_gpu": 1,
        "ppo_mini_batch_size": 128,
        "profiler": {
          "all_ranks": false,
          "discrete": false,
          "ranks": null
        },
        "shuffle": false,
        "strategy": "fsdp",
        "ulysses_sequence_parallel_size": 2,
        "use_dynamic_bsz": true,
        "use_kl_loss": true,
        "use_torch_compile": true
      },
      "hybrid_engine": true,
      "model": {
        "custom_chat_template": null,
        "enable_activation_offload": false,
        "enable_gradient_checkpointing": true,
        "external_lib": null,
        "fused_kernel_options": {
          "impl_backend": "torch"
        },
        "lora_alpha": 16,
        "lora_rank": 0,
        "path": "/lustre/fsw/portfolios/llmservice/users/wedu/models/final_hf_checkpoint_150",
        "target_modules": "all-linear",
        "trust_remote_code": false,
        "use_fused_kernels": false,
        "use_liger": false,
        "use_remove_padding": true,
        "use_shm": false
      },
      "ref": {
        "entropy_checkpointing": false,
        "entropy_from_logits_with_chunking": false,
        "fsdp_config": {
          "forward_prefetch": false,
          "param_offload": true,
          "reshard_after_forward": true,
          "wrap_policy": {
            "min_num_params": 0
          }
        },
        "log_prob_max_token_len_per_gpu": 16384,
        "log_prob_micro_batch_size": null,
        "log_prob_micro_batch_size_per_gpu": null,
        "log_prob_use_dynamic_bsz": true,
        "profiler": {
          "all_ranks": false,
          "discrete": false,
          "ranks": null
        },
        "strategy": "fsdp",
        "ulysses_sequence_parallel_size": 2,
        "use_torch_compile": true
      },
      "rollout": {
        "agent": {
          "num_workers": 8
        },
        "calculate_log_probs": false,
        "disable_log_stats": true,
        "do_sample": true,
        "dtype": "bfloat16",
        "enable_chunked_prefill": true,
        "enforce_eager": false,
        "engine_kwargs": {
          "sglang": {
            "attention_backend": null
          },
          "vllm": {
            "disable_mm_preprocessor_cache": false,
            "swap_space": null
          }
        },
        "free_cache_engine": false,
        "gpu_memory_utilization": 0.7,
        "ignore_eos": false,
        "layered_summon": false,
        "load_format": "dummy_dtensor",
        "log_prob_max_token_len_per_gpu": 16384,
        "log_prob_micro_batch_size": null,
        "log_prob_micro_batch_size_per_gpu": 1,
        "log_prob_use_dynamic_bsz": true,
        "max_model_len": null,
        "max_num_batched_tokens": 8192,
        "max_num_seqs": 32,
        "mode": "sync",
        "multi_stage_wake_up": false,
        "multi_turn": {
          "completion_callback": null,
          "enable": false,
          "format": "hermes",
          "interaction_config_path": null,
          "max_assistant_turns": null,
          "max_parallel_calls": 1,
          "max_tool_response_length": 256,
          "max_user_turns": null,
          "tokenization_sanity_check_mode": "strict",
          "tool_config_path": null,
          "tool_response_truncate_side": "middle",
          "use_inference_chat_template": false
        },
        "n": 16,
        "name": "vllm",
        "profiler": {
          "all_ranks": false,
          "discrete": false,
          "ranks": null
        },
        "prompt_length": 1024,
        "response_length": 16384,
        "temperature": 1,
        "tensor_model_parallel_size": 2,
        "top_k": -1,
        "top_p": 1,
        "use_fire_sampling": false,
        "val_kwargs": {
          "do_sample": false,
          "n": 1,
          "temperature": 0,
          "top_k": -1,
          "top_p": 1
        }
      }
    }
  },
  "algorithm": {
    "value": {
      "adv_estimator": "grpo",
      "gamma": 1,
      "kl_ctrl": {
        "horizon": 10000,
        "kl_coef": 0,
        "target_kl": 0.1,
        "type": "fixed"
      },
      "kl_penalty": "kl",
      "lam": 1,
      "norm_adv_by_std_in_grpo": true,
      "normalize_advantage": true,
      "pf_ppo": {
        "reweight_method": "pow",
        "weight_pow": 2
      },
      "use_kl_in_reward": false,
      "use_pf_ppo": false
    }
  },
  "critic": {
    "value": {
      "checkpoint": {
        "load_contents": [
          "model",
          "optimizer",
          "extra"
        ],
        "save_contents": [
          "model",
          "optimizer",
          "extra"
        ]
      },
      "cliprange_value": 0.5,
      "forward_max_token_len_per_gpu": 32768,
      "forward_micro_batch_size": null,
      "forward_micro_batch_size_per_gpu": null,
      "grad_clip": 1,
      "loss_agg_mode": "token-mean",
      "model": {
        "enable_activation_offload": false,
        "enable_gradient_checkpointing": true,
        "external_lib": null,
        "fsdp_config": {
          "forward_prefetch": false,
          "fsdp_size": -1,
          "offload_policy": false,
          "optimizer_offload": false,
          "param_offload": false,
          "reshard_after_forward": true,
          "wrap_policy": {
            "min_num_params": 0
          }
        },
        "lora_alpha": 16,
        "lora_rank": 0,
        "path": "~/models/deepseek-llm-7b-chat",
        "target_modules": "all-linear",
        "tokenizer_path": "/lustre/fsw/portfolios/llmservice/users/wedu/models/final_hf_checkpoint_150",
        "trust_remote_code": false,
        "use_remove_padding": false,
        "use_shm": false
      },
      "optim": {
        "lr": 0.00001,
        "lr_warmup_steps_ratio": 0,
        "min_lr_ratio": null,
        "total_training_steps": 10770,
        "warmup_style": "constant",
        "weight_decay": 0.01
      },
      "ppo_epochs": 1,
      "ppo_max_token_len_per_gpu": 32768,
      "ppo_micro_batch_size": null,
      "ppo_micro_batch_size_per_gpu": null,
      "ppo_mini_batch_size": 128,
      "profiler": {
        "all_ranks": false,
        "discrete": false,
        "ranks": null
      },
      "rollout_n": 16,
      "shuffle": false,
      "strategy": "fsdp",
      "ulysses_sequence_parallel_size": 1,
      "use_dynamic_bsz": true
    }
  },
  "custom_reward_function": {
    "value": {
      "name": "compute_score",
      "path": null
    }
  },
  "data": {
    "value": {
      "custom_cls": {
        "name": null,
        "path": null
      },
      "filter_overlong_prompts": false,
      "filter_overlong_prompts_workers": 1,
      "filter_prompts": false,
      "image_key": "images",
      "max_prompt_length": 1024,
      "max_response_length": 16384,
      "prompt_key": "prompt",
      "return_full_prompt": false,
      "return_raw_chat": false,
      "return_raw_input_ids": false,
      "reward_fn_key": "data_source",
      "shuffle": false,
      "tokenizer": null,
      "train_batch_size": 128,
      "train_files": "/lustre/fsw/portfolios/llmservice/users/geshen/match/acemath_rl_46k_grpo_original_verl_shuffled.parquet",
      "truncation": "right",
      "trust_remote_code": false,
      "use_shm": false,
      "val_batch_size": 512,
      "val_files": "/lustre/fsw/portfolios/llmservice/users/geshen/match/acemath_rl_46k_grpo_original_verl_shuffled.parquet",
      "validation_shuffle": false,
      "video_key": "videos"
    }
  },
  "ray_init": {
    "value": {
      "num_cpus": null,
      "timeline_json_file": null
    }
  },
  "reward_model": {
    "value": {
      "enable": false,
      "forward_max_token_len_per_gpu": 32768,
      "launch_reward_fn_async": false,
      "max_length": null,
      "micro_batch_size": null,
      "micro_batch_size_per_gpu": null,
      "model": {
        "external_lib": null,
        "fsdp_config": {
          "forward_prefetch": false,
          "fsdp_size": -1,
          "param_offload": false,
          "reshard_after_forward": true,
          "wrap_policy": {
            "min_num_params": 0
          }
        },
        "input_tokenizer": "/lustre/fsw/portfolios/llmservice/users/wedu/models/final_hf_checkpoint_150",
        "path": "~/models/FsfairX-LLaMA3-RM-v0.1",
        "trust_remote_code": false,
        "use_fused_kernels": false,
        "use_remove_padding": false,
        "use_shm": false
      },
      "profiler": {
        "all_ranks": false,
        "discrete": false,
        "ranks": null
      },
      "reward_manager": "naive",
      "sandbox_fusion": {
        "max_concurrent": 64,
        "memory_limit_mb": 1024,
        "url": null
      },
      "strategy": "fsdp",
      "ulysses_sequence_parallel_size": 1,
      "use_dynamic_bsz": true
    }
  },
  "trainer": {
    "value": {
      "balance_batch": true,
      "controller_nsight_options": {
        "cuda-graph-trace": "graph",
        "cuda-memory-usage": "true",
        "trace": "cuda,nvtx,cublas,ucx"
      },
      "critic_warmup": 0,
      "default_hdfs_dir": null,
      "default_local_dir": "/experiments/grpo-nnodes_16-tp_2-16k-7B-run_10-rollout-16-lr-1e-06-7B-t-0.6-kl-0.0-deepseek-7b-verl-t1-fixed-ordering-v3/checkpoints",
      "del_local_ckpt_after_load": false,
      "device": "cuda",
      "esi_redundant_time": 0,
      "experiment_name": "grpo-nnodes_16-tp_2-16k-7B-run_10-rollout-16-lr-1e-06-7B-t-0.6-kl-0.0-deepseek-7b-verl-t1-fixed-ordering-v3",
      "log_val_generations": 0,
      "logger": [
        "console",
        "wandb"
      ],
      "max_actor_ckpt_to_keep": null,
      "max_critic_ckpt_to_keep": null,
      "n_gpus_per_node": 8,
      "nnodes": 16,
      "profile_steps": null,
      "project_name": "geshen-verl",
      "ray_wait_register_center_timeout": 300,
      "resume_from_path": null,
      "resume_mode": "auto",
      "rollout_data_dir": "/experiments/grpo-nnodes_16-tp_2-16k-7B-run_10-rollout-16-lr-1e-06-7B-t-0.6-kl-0.0-deepseek-7b-verl-t1-fixed-ordering-v3/checkpoints/rollout_data_dir",
      "save_freq": 10,
      "test_freq": 50000,
      "timeout": "00:03:45:00",
      "total_epochs": 30,
      "total_training_steps": null,
      "val_before_train": false,
      "val_generations_to_log_to_wandb": 1,
      "val_only": false,
      "validation_data_dir": null,
      "worker_nsight_options": {
        "capture-range": "cudaProfilerApi",
        "capture-range-end": null,
        "cuda-graph-trace": "graph",
        "cuda-memory-usage": "true",
        "kill": "none",
        "trace": "cuda,nvtx,cublas,ucx"
      }
    }
  }
}