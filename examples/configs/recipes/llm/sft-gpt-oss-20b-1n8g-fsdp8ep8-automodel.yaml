defaults: ../../sft.yaml
cluster:
  gpus_per_node: 8
policy:
  model_name: openai/gpt-oss-20b
  train_global_batch_size: 128
  train_micro_batch_size: 8
  max_total_sequence_length: 512
  dequantize_base_checkpoint: true
  dtensor_cfg:
    expert_parallel_size: 8
    automodel_kwargs:
      backend:
        _target_: nemo_automodel.components.moe.utils.BackendConfig
        attn: flex
        linear: te
        rms_norm: te
        enable_deepep: true
        fake_balanced_gate: false
        enable_hf_state_dict_adapter: true
checkpointing:
  checkpoint_dir: results/sft-gpt-oss-20b-1n8g-fsdp8ep8-automodel
