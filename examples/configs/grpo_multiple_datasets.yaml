# GRPO Algorithm Configuration
defaults: "grpo_math_1B.yaml"

data:
  _override_: true # override the data config instead of merging with it

  max_input_seq_length: ${policy.max_total_sequence_length} # upper bound, real truncation occurs at vllm.max_model_len
  shuffle: true
  num_workers: 1

  # use multiple dataloader for train
  # see https://github.com/NVIDIA-NeMo/RL/blob/main/docs/guides/grpo.md#multiple-dataloaders for more details.
  use_multiple_dataloader: false
  num_prompts_per_dataloader: 16
  custom_dataloader: examples.custom_dataloader.custom_dataloader.example_custom_dataloader

  # dataset
  # See https://github.com/NVIDIA-NeMo/RL/blob/main/docs/guides/sft.md#datasets for more details.
  train:
    - dataset_name: OpenMathInstruct-2
      split_validation_size: 0.05 # use 5% of the training data as validation data
      seed: ${grpo.seed} # seed for train/validation split when split_validation_size > 0
    - dataset_name: DeepScaler
  validation:
    - dataset_name: AIME2024
      repeat: 16
    - dataset_name: DAPOMathAIME2024

  # default settings for all datasets
  default:
    prompt_file: "examples/prompts/cot.txt"
    system_prompt_file: null
    processor: "math_hf_data_processor"
    env_name: "math"
