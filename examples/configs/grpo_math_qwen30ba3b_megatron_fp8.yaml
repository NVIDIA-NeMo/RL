# GRPO Algorithm Configuration
defaults: "grpo_math_qwen30ba3b_megatron.yaml"

loss_fn:
  use_importance_sampling_correction: true

policy:
  sequence_packing:
    enabled: true

  megatron_cfg:
    moe_router_dtype: fp32
    tensor_model_parallel_size: 1
    sequence_parallel: false
    context_parallel_size: 1
    pipeline_model_parallel_size: 2
    
    fp8_cfg:
      enabled: true
      fp8: "e4m3"
      fp8_recipe: "blockwise"
      fp8_param: false

    optimizer:
      use_precision_aware_optimizer: false
    
    env_vars:
      NVTE_FP8_BLOCK_SCALING_FP32_SCALES: "1"

  generation:
    vllm_cfg:
      tensor_parallel_size: 2
      precision: "fp8"
      use_deep_gemm: true
      gpu_memory_utilization: 0.5