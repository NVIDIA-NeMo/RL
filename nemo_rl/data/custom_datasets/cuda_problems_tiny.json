[
    {"problem": "import torch\nimport torch.nn as nn\n\n\nclass Model(nn.Module):\n    '''\n    Model that applies Layer Normalization followed by Swish activation.\n    Swish activation is implemented as x * sigmoid(x).\n    '''\n\n    def __init__(self, hidden_dim, eps=1e-5):\n        super(Model, self).__init__()\n        self.weight = nn.Parameter(torch.randn(hidden_dim, dtype=torch.float16))\n        self.bias = nn.Parameter(torch.randn(hidden_dim, dtype=torch.float16))\n        self.eps = eps\n        self.hidden_dim = hidden_dim\n\n    def forward(self, x):\n        # Apply layer normalization with custom weight and bias\n        norm = torch.nn.functional.layer_norm(\n            x,\n            normalized_shape=(self.hidden_dim,),\n            weight=self.weight,\n            bias=self.bias,\n            eps=self.eps,\n        )\n        # Apply swish activation (x * sigmoid(x))\n        return x * torch.sigmoid(norm)\n\n\n# Model parameters\nbatch_size = 4096\nhidden_dim = 512\neps = 1e-05\n\n\ndef get_inputs():\n    return [torch.randn([batch_size, hidden_dim], dtype=torch.float16, device=\"cuda\")]\n\n\ndef get_init_inputs():\n    return [hidden_dim, eps]\n"}
]