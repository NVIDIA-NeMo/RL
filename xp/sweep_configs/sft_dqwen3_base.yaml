# Sample sweep configuration for GRPO math experiments
# Each parameter can have a list of values to sweep over
# The launcher will generate all possible combinations

# Required parameter that must match the target script name
script_path: "examples/run_sft.py"

# Optional: Path to the base YAML config file
# Can be overridden by the --config command-line argument
# If null and --config is not provided, no base config will be used
config_path: "examples/configs/sft_mdlm.yaml" 


# Model configuration
policy.is_mdlm: [false]   # let's see if things work right out of the box
policy.model_name: ["nvidia/Nemotron-Diffusion-Research-4B-v0"]

# Data configuration
data.dataset_name: ["prompt_response_dataset"]
data.input_key: ["question"]
data.output_key: ["answer"]
data.train_data_path: ["/workspace/data/gsm8k/train.jsonl"]
data.val_data_path: ["/workspace/data/gsm8k/test.jsonl"]

# Training steps
sft.max_num_epochs: [100]
sft.max_num_steps: [10000]

# Resources
cluster.num_nodes: [1]
cluster.gpus_per_node: [8]

# Training configuration
policy.train_global_batch_size: [64]
policy.train_micro_batch_size: [4]
policy.max_total_sequence_length: [1024]

# Learning rate
policy.optimizer.kwargs.lr: [1e-5, 1e-6]
