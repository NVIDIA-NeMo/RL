# Sample sweep configuration for GRPO math experiments
# Each parameter can have a list of values to sweep over
# The launcher will generate all possible combinations

# Required parameter that must match the target script name
script_path: "examples/run_sft.py"

# Optional: Path to the base YAML config file
# Can be overridden by the --config command-line argument
# If null and --config is not provided, no base config will be used
config_path: "examples/configs/sft_mdlm.yaml" 


# Model configuration
policy.is_mdlm: [true]
policy.is_dqwn: [true]
policy.model_name: ["nvidia/Nemotron-Diffusion-Research-4B-v0"]

# Data configuration
data.dataset_name: ["openmathinstruct2"]
data.split: ["train_1M"]
data.prompt_file: ["examples/prompts/math.txt"]
data.input_key: ["problem"]
data.output_key: ["generated_solution"]

# Training steps
sft.max_num_epochs: [100]
sft.max_num_steps: [10000]

# Resources
cluster.num_nodes: [1]
cluster.gpus_per_node: [8]

# Training configuration
policy.train_global_batch_size: [64]
policy.train_micro_batch_size: [4]
policy.max_total_sequence_length: [4096]

# Learning rate
policy.optimizer.kwargs.lr: [3e-5]
