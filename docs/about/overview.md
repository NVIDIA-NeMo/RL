# Overview

**NeMo RL** is an open-source post-training library within the [NeMo Framework](https://github.com/NVIDIA-NeMo), designed to streamline and scale reinforcement learning methods for multimodal models (LLMs, VLMs, etc.). Designed for flexibility, reproducibility, and scale, NeMo RL enables both small-scale experiments and massive multi-GPU, multi-node deployments for fast experimentation in research and production environments.

## What You Can Expect

- **Flexibility** with a modular design that allows easy integration and customization.
- **Efficient resource management using Ray**, enabling scalable and flexible deployment across different hardware configurations.
- **Hackable** with native PyTorch-only paths for quick research prototypes.
- **High performance with Megatron Core**, supporting various parallelism techniques for large models and large context lengths.
- **Seamless integration with Hugging Face** for ease of use, allowing users to leverage a wide range of pre-trained models and tools.
- **Comprehensive documentation** that is both detailed and user-friendly, with practical examples.

For more details on the architecture and design philosophy, see the [design documents](../design-docs/design-and-philosophy.md).

## Releases

For a complete list of releases and detailed changelogs, visit the [GitHub Releases page](https://github.com/NVIDIA-NeMo/RL/releases).
